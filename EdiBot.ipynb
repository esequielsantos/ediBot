{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7v_XiF74qFSj"
      ],
      "authorship_tag": "ABX9TyMsVrFpvbvkVwZzG851Ou48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esequielsantos/ediBot/blob/main/EdiBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EdiBot\n",
        "###Segue requisitos e uso da API\n",
        "Instalar Gemini\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HLrsLWuTmTkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdbMsHHbmMot"
      },
      "outputs": [],
      "source": [
        "!pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up my API key\n",
        "\n",
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n",
        "\n",
        "<a class=\"button\" href=\"https://aistudio.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"üîë\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:\n"
      ],
      "metadata": {
        "id": "3GkRM95ZmZBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "Uwn3IeH9nKcP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar modelos disponiveis\n"
      ],
      "metadata": {
        "id": "60cHJAVPni31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_tuned_models():\n",
        "  print (m)"
      ],
      "metadata": {
        "id": "1rv_pDZQZ4Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "3tRmM_KtnnEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando o modelo\n",
        "Temperaura:"
      ],
      "metadata": {
        "id": "KITrkVypqeoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 1,\n",
        "}"
      ],
      "metadata": {
        "id": "LsLj6QLFqiNO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguran√ßa:"
      ],
      "metadata": {
        "id": "pjiAtqjZr91j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saf_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "BHt1bL2ErCNW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usar **modelo** escolhido acima"
      ],
      "metadata": {
        "id": "7hncyqUspfoH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s-JqXcDe2hZ_"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro-latest', safety_settings= saf_settings, generation_config= gen_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Enviando mensagem ao modelo"
      ],
      "metadata": {
        "id": "7v_XiF74qFSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Estou programndo em Phyton. Sugira 5 op√ß√µes indispens√°veis de conhecermos no aprendizado de Phyton\")\n",
        "#print(model.generate_content(\"Estou programndo em Phyton. Sugira 5 op√ß√µes indispens√°veis de conhecermos no aprendizado de Phyton\").text)"
      ],
      "metadata": {
        "id": "Vya97xSYqOgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exibindo Resposta"
      ],
      "metadata": {
        "id": "BQT5u69dqQzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ZvE1AjS7qUEZ",
        "outputId": "ad7fe00e-53fa-44ed-90bb-a3506965b30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'response' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-bd5c97ae99ef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EdiBOT\n",
        "\n",
        "> Adicionar aspas INICIANDO O EdiBot\n",
        "\n",
        "**Iniciando**\n",
        "\n"
      ],
      "metadata": {
        "id": "V4lh5-7LtWFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "hNyByEk5Oa1L"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Rode o comando abaixo para limpar o historico do chat*"
      ],
      "metadata": {
        "id": "Q2lkUTF2fFVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "_DQDwtpxthTG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edibot(prompt, history):\n",
        "  if not chat.history:\n",
        "    agora = datetime.now()\n",
        "    agorastr= formatted_string = f\"{agora:%d/%m/%Y %H:%M:%S}\"\n",
        "    hora = agora.hour - 3\n",
        "    periodo_dia = \"\"\n",
        "    if 6 <= hora < 12:\n",
        "      periodo_dia = \"manh√£\"\n",
        "    elif 12 <= hora < 18:\n",
        "      periodo_dia = \"tarde\"\n",
        "    else:\n",
        "      periodo_dia = \"noite\"\n",
        "    bemvindo = model.generate_content(f\"Voc√™ √© um atendente de uma Loja f√≠sica de informatica chamada ByteMe, que vende computadores, laptops e acess√≥rios chamado EdiBot. Escreva uma mensagem de sauda√ß√£o de {periodo_dia} \").text\n",
        "    response = chat.send_message(prompt)\n",
        "    return agorastr + '\\n\\n' + bemvindo + '\\n\\n-----------------------\\n' + response.text\n",
        "  else:\n",
        "    prompt = prompt.lower()\n",
        "    agradecer = model.generate_content(\"Voc√™ √© um atendente de uma empresa de informatica chamada ByteMe. Escreva uma mensagem curta de agradecimento por ter entrado em contato\").text\n",
        "    if prompt == \"history\":\n",
        "      markdown_text = \"\"\n",
        "      for message in chat.history:\n",
        "        sender = message.role\n",
        "        text = message.parts[0]\n",
        "        markdown_text += f\"* **{sender}**: *{text}*\\n\"\n",
        "      return markdown_text\n",
        "    elif 'obrigado' in prompt:\n",
        "      return agradecer\n",
        "    elif 'tchau' in prompt:\n",
        "      return agradecer\n",
        "    elif 'fim' in prompt:\n",
        "      return agradecer\n",
        "    elif 'sair' in prompt:\n",
        "      return agradecer\n",
        "    else:\n",
        "      response = chat.send_message(prompt)\n",
        "      return response.text\n",
        "  #continuar = model.generate_content(\"Escreva uma mensagem curta e agradav√©l perguntando se deseja mais alguma informa√ß√£o\").text\n",
        "  #return continuar"
      ],
      "metadata": {
        "id": "Cq8A1hWnt0pk"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Teste da funcao inteligente\n",
        "*Exige parada total do GRadio*"
      ],
      "metadata": {
        "id": "4SDZSZk_RB-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(edibot(\"Bom dia, preciso de um computador novo para jogar\", []))"
      ],
      "metadata": {
        "id": "ZdcpNSQ5REXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(edibot(\"e se for pra usar Autocad ?\", []))"
      ],
      "metadata": {
        "id": "vgVukT_sWlRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(edibot('history', []))\n",
        "#chat.history"
      ],
      "metadata": {
        "id": "xHaUwnsba5NR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "85bdda4a-4635-4103-f388-59709976db2f"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* **user**: *text: \"Bom dia, preciso de um computador novo para jogar\"\n",
            "*\n",
            "* **model**: *text: \"**Recomenda\\303\\247\\303\\265es de Computadores para Jogos**\\n\\n**Faixa de Pre\\303\\247os M\\303\\251dia (R$ 3.000 - R$ 5.000)**\\n\\n* **Lenovo Legion 5 (15 polegadas)**\\n  * Processador: AMD Ryzen 5 5600H\\n  * Placa de v\\303\\255deo: NVIDIA GeForce GTX 1650\\n  * RAM: 8 GB DDR4\\n  * Armazenamento: SSD de 256 GB\\n* **Dell G15 5515 (15 polegadas)**\\n  * Processador: Intel Core i5-11400H\\n  * Placa de v\\303\\255deo: NVIDIA GeForce GTX 1650 Ti\\n  * RAM: 8 GB DDR4\\n  * Armazenamento: SSD de 256 GB + HDD de 1 TB\\n\\n**Faixa de Pre\\303\\247os Alta (R$ 5.000 - R$ 8.000)**\\n\\n* **ASUS ROG Strix G15 (15 polegadas)**\\n  * Processador: AMD Ryzen 7 5800H\\n  * Placa de v\\303\\255deo: NVIDIA GeForce RTX 3050\\n  * RAM: 16 GB DDR4\\n  * Armazenamento: SSD de 512 GB\\n* **MSI Katana GF66 (15 polegadas)**\\n  * Processador: Intel Core i7-11800H\\n  * Placa de v\\303\\255deo: NVIDIA GeForce RTX 3060\\n  * RAM: 16 GB DDR4\\n  * Armazenamento: SSD de 512 GB\\n\\n**Faixa de Pre\\303\\247os Premium (R$ 8.000+)**\\n\\n* **Razer Blade 15 (15 polegadas)**\\n  * Processador: Intel Core i9-11900H\\n  * Placa de v\\303\\255deo: NVIDIA GeForce RTX 3080\\n  * RAM: 32 GB DDR4\\n  * Armazenamento: SSD de 1 TB\\n* **Alienware m15 R5 (15 polegadas)**\\n  * Processador: AMD Ryzen 9 5900HX\\n  * Placa de v\\303\\255deo: NVIDIA GeForce RTX 3070\\n  * RAM: 32 GB DDR4\\n  * Armazenamento: SSD de 1 TB\\n\\n**Especifica\\303\\247\\303\\265es Recomendadas**\\n\\n* **Processador:** M\\303\\255nimo Intel Core i5-10300H ou AMD Ryzen 5 5600H\\n* **Placa de v\\303\\255deo:** M\\303\\255nimo NVIDIA GeForce GTX 1650 ou AMD Radeon RX 5500M\\n* **RAM:** M\\303\\255nimo 8 GB DDR4 ou DDR5\\n* **Armazenamento:** SSD de 256 GB ou mais\\n* **Tela:** 15,6 polegadas ou maior, com uma taxa de atualiza\\303\\247\\303\\243o de pelo menos 144Hz\\n* **Outros:** Teclado retroiluminado, Wi-Fi 6, portas USB 3.0 ou 3.1\"\n",
            "*\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Uso do GRADIO"
      ],
      "metadata": {
        "id": "sh69Q2xahcVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4mgmMdAt7WQ"
      },
      "outputs": [],
      "source": [
        "!pip install -U gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "3o_zOvN_iDMd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tela Gr√°fica para o BOT"
      ],
      "metadata": {
        "id": "9ooAl5x2iTTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.ChatInterface(edibot,\n",
        "                 title='BatePapo BiteMe',\n",
        "                 textbox=gr.Textbox(placeholder=\"Pergunte ao EdiBOT\"),\n",
        "                 retry_btn='Voltar',\n",
        "                 clear_btn='Limpar',\n",
        "                 undo_btn='Desfazer',\n",
        "                 stop_btn='Parar',\n",
        "                 submit_btn='Enviar [Enter]')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "QpUOp2JciYtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "45a50de5-48cc-4a42-a8f0-7e51b490d0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://f55dac2fe297d670f5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f55dac2fe297d670f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subir para o GitHub"
      ],
      "metadata": {
        "id": "eh6GfbuM1oXq"
      }
    }
  ]
}