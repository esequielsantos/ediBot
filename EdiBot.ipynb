{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVBh8EVI/d6FiPFsE2qAjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esequielsantos/ediBot/blob/main/EdiBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar Gemini\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HLrsLWuTmTkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rdbMsHHbmMot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550c7be6-8f5f-4cdd-8b3f-de096adebdda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.18.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up my API key\n",
        "\n",
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n",
        "\n",
        "<a class=\"button\" href=\"https://aistudio.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:\n"
      ],
      "metadata": {
        "id": "3GkRM95ZmZBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "Uwn3IeH9nKcP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar modelos disponiveis\n"
      ],
      "metadata": {
        "id": "60cHJAVPni31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "3tRmM_KtnnEB",
        "outputId": "daec4d52-5c81-426f-cb88-368e36d76b38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando o modelo\n",
        "Temperaura:"
      ],
      "metadata": {
        "id": "KITrkVypqeoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "LsLj6QLFqiNO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segurança:"
      ],
      "metadata": {
        "id": "pjiAtqjZr91j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saf_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "BHt1bL2ErCNW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usar **modelo** escolhido acima"
      ],
      "metadata": {
        "id": "7hncyqUspfoH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s-JqXcDe2hZ_"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro-latest', safety_settings= saf_settings, generation_config= gen_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enviando mensagem ao modelo"
      ],
      "metadata": {
        "id": "7v_XiF74qFSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Estou programndo em Phyton. Sugira 5 opções indispensáveis de conhecermos no aprendizado de Phyton\")\n",
        "#print(model.generate_content(\"Estou programndo em Phyton. Sugira 5 opções indispensáveis de conhecermos no aprendizado de Phyton\").text)"
      ],
      "metadata": {
        "id": "Vya97xSYqOgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exibindo Resposta"
      ],
      "metadata": {
        "id": "BQT5u69dqQzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvE1AjS7qUEZ",
        "outputId": "d69c5f35-a461-4f84-9ccd-c91661378bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 Opções Indispensáveis para o Aprendizado de Python:\n",
            "\n",
            "1. **Listas de Compreensão:** Uma sintaxe concisa para criar novas listas a partir de elementos existentes, filtrando e transformando-os.\n",
            "2. **Dicionários:** Estruturas de dados que mapeiam chaves para valores, permitindo acesso rápido e fácil a dados com base em chaves.\n",
            "3. **Funções Lambda:** Funções anônimas de uma linha que podem ser usadas como argumentos para outras funções ou armazenadas em variáveis.\n",
            "4. **Geradores:** Objetos iteráveis que produzem valores sob demanda, economizando memória e melhorando a eficiência.\n",
            "5. **Módulos:** Arquivos Python que contêm funções, classes e variáveis que podem ser importados para reutilização em outros programas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Adicionar aspas INICIANDO O EdiBot\n",
        "\n",
        "**Iniciando**\n",
        "\n"
      ],
      "metadata": {
        "id": "V4lh5-7LtWFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "_DQDwtpxthTG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "hNyByEk5Oa1L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edibot(prompt, history):\n",
        "  if not chat.history:\n",
        "    # Obter o horário atual\n",
        "    agora = datetime.now()\n",
        "\n",
        "    # Extrair a hora do horário atual\n",
        "    hora = agora.hour\n",
        "\n",
        "    # Definir a variável do período do dia\n",
        "    periodo_dia = \"\"\n",
        "\n",
        "    # Verificar o período do dia\n",
        "    if 6 <= hora < 12:\n",
        "      periodo_dia = \"manhã\"\n",
        "    elif 12 <= hora < 18:\n",
        "      periodo_dia = \"tarde\"\n",
        "    else:\n",
        "      periodo_dia = \"noite\"\n",
        "\n",
        "    bemvindo = model.generate_content(f\"Você é um atendente de uma empresa de informatica chamada ByteMe chamado EdiBot. Escreva uma mensagem de saudação de {periodo_dia} \").text\n",
        "    response = chat.send_message(prompt)\n",
        "    return bemvindo + '\\n\\n-----------------------\\n' + response.text\n",
        "  else:\n",
        "    prompt = prompt.lower()\n",
        "    agradecer = model.generate_content(\"Você é um atendente de uma empresa de informatica chamada ByteMe. Escreva uma mensagem curta de agradecimento por ter entrado em contato\").text\n",
        "    if prompt == \"history\":\n",
        "        return chat.history\n",
        "    elif 'obrigado' in prompt:\n",
        "      return agradecer\n",
        "    elif 'tchau' in prompt:\n",
        "      return agradecer\n",
        "    elif 'fim' in prompt:\n",
        "      return agradecer\n",
        "    elif prompt == \"next\":\n",
        "      continuar = model.generate_content(\"Escreva uma mensagem curta e agradavél perguntando se deseja mais alguma informação\").text\n",
        "      return continuar\n",
        "    else:\n",
        "      response = chat.send_message(prompt)\n",
        "      return response.text"
      ],
      "metadata": {
        "id": "Cq8A1hWnt0pk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste da funcao inteligente"
      ],
      "metadata": {
        "id": "4SDZSZk_RB-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(edibot(\"Bom dia, preciso de um computador novo para jogar\", []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "ZdcpNSQ5REXK",
        "outputId": "9f650af4-a04a-4fdd-fc54-da7ecb4804e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**EdiBot:** Boa tarde, estimado cliente! Seja bem-vindo à ByteMe. Estou aqui para ajudá-lo com qualquer necessidade de TI que você possa ter. Como posso atendê-lo hoje?\n",
            "\n",
            "-----------------------\n",
            "**Configuração de computador recomendada para jogos:**\n",
            "\n",
            "**Processador:**\n",
            "* Intel Core i5-12600K ou AMD Ryzen 5 5600X\n",
            "\n",
            "**Placa de vídeo:**\n",
            "* NVIDIA GeForce RTX 3060 Ti ou AMD Radeon RX 6700 XT\n",
            "\n",
            "**Memória RAM:**\n",
            "* 16 GB de DDR4-3200 ou DDR5-4800\n",
            "\n",
            "**Armazenamento:**\n",
            "* SSD NVMe de 512 GB ou 1 TB\n",
            "\n",
            "**Fonte de alimentação:**\n",
            "* 650W ou 750W 80+ Gold ou Platinum\n",
            "\n",
            "**Gabinete:**\n",
            "* Com fluxo de ar adequado e suporte para componentes de alto desempenho\n",
            "\n",
            "**Sistema operacional:**\n",
            "* Windows 10 ou 11 de 64 bits\n",
            "\n",
            "**Configuração adicional para jogos em alta resolução ou com altas taxas de quadros:**\n",
            "\n",
            "* **Processador:** Intel Core i7-12700K ou AMD Ryzen 7 5800X\n",
            "* **Placa de vídeo:** NVIDIA GeForce RTX 3070 Ti ou AMD Radeon RX 6800 XT\n",
            "* **Memória RAM:** 32 GB de DDR4-3600 ou DDR5-5200\n",
            "* **Armazenamento:** SSD NVMe de 1 TB ou 2 TB\n",
            "\n",
            "**Dicas adicionais:**\n",
            "\n",
            "* Considere uma placa-mãe com um bom sistema de fornecimento de energia (VRM) para suportar processadores de alto desempenho.\n",
            "* Escolha uma placa de vídeo com memória de vídeo dedicada suficiente para os jogos que você deseja jogar.\n",
            "* Aumente a memória RAM se você planeja executar vários programas ou jogos simultaneamente.\n",
            "* Um SSD NVMe oferece tempos de carregamento mais rápidos e melhor desempenho geral.\n",
            "* Certifique-se de que seu gabinete tenha espaço suficiente para todos os componentes e permita um fluxo de ar adequado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(edibot(\"e se for computador novo para jogar\", []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "zGtokvRyUZ4J",
        "outputId": "b2e2fdfa-4e0b-48ad-c203-da25b181ffe5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Configuração de computador novo recomendada para jogos:**\n",
            "\n",
            "**Processador:**\n",
            "* Intel Core i5-13600K ou AMD Ryzen 5 7600X\n",
            "\n",
            "**Placa de vídeo:**\n",
            "* NVIDIA GeForce RTX 4070 Ti ou AMD Radeon RX 7900 XT\n",
            "\n",
            "**Memória RAM:**\n",
            "* 16 GB de DDR5-6000 ou DDR4-3600\n",
            "\n",
            "**Armazenamento:**\n",
            "* SSD NVMe de 1 TB ou 2 TB\n",
            "\n",
            "**Fonte de alimentação:**\n",
            "* 750W ou 850W 80+ Gold ou Platinum\n",
            "\n",
            "**Gabinete:**\n",
            "* Com fluxo de ar adequado e suporte para componentes de alto desempenho\n",
            "\n",
            "**Sistema operacional:**\n",
            "* Windows 11 de 64 bits\n",
            "\n",
            "**Configuração adicional para jogos em alta resolução ou com altas taxas de quadros:**\n",
            "\n",
            "* **Processador:** Intel Core i7-13700K ou AMD Ryzen 7 7700X\n",
            "* **Placa de vídeo:** NVIDIA GeForce RTX 4080 ou AMD Radeon RX 7900 XTX\n",
            "* **Memória RAM:** 32 GB de DDR5-6400 ou DDR4-4000\n",
            "* **Armazenamento:** SSD NVMe de 2 TB ou 4 TB\n",
            "\n",
            "**Dicas adicionais:**\n",
            "\n",
            "* Considere uma placa-mãe com um bom sistema de fornecimento de energia (VRM) para suportar processadores de alto desempenho.\n",
            "* Escolha uma placa de vídeo com memória de vídeo dedicada suficiente para os jogos que você deseja jogar.\n",
            "* Aumente a memória RAM se você planeja executar vários programas ou jogos simultaneamente.\n",
            "* Um SSD NVMe oferece tempos de carregamento mais rápidos e melhor desempenho geral.\n",
            "* Certifique-se de que seu gabinete tenha espaço suficiente para todos os componentes e permita um fluxo de ar adequado.\n",
            "\n",
            "Esta configuração fornecerá um desempenho excelente para jogos modernos em altas resoluções e taxas de quadros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(edibot(\"e se for pra usar Autocad ?\", []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "vgVukT_sWlRU",
        "outputId": "54e9ee5d-bf04-4d87-95c3-f91b65aea4cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Configuração de computador recomendada para AutoCAD:**\n",
            "\n",
            "**Processador:**\n",
            "* Intel Core i5-12600K ou AMD Ryzen 5 5600X\n",
            "\n",
            "**Placa de vídeo:**\n",
            "* NVIDIA GeForce RTX 3060 ou AMD Radeon RX 6600 XT (para renderização 3D aprimorada)\n",
            "\n",
            "**Memória RAM:**\n",
            "* 16 GB de DDR4-3200 ou DDR5-4800\n",
            "\n",
            "**Armazenamento:**\n",
            "* SSD NVMe de 512 GB ou 1 TB\n",
            "\n",
            "**Fonte de alimentação:**\n",
            "* 650W ou 750W 80+ Gold ou Platinum\n",
            "\n",
            "**Gabinete:**\n",
            "* Com fluxo de ar adequado e suporte para componentes de alto desempenho\n",
            "\n",
            "**Sistema operacional:**\n",
            "* Windows 10 ou 11 de 64 bits\n",
            "\n",
            "**Configuração adicional para trabalhos complexos do AutoCAD:**\n",
            "\n",
            "* **Processador:** Intel Core i7-12700K ou AMD Ryzen 7 5800X\n",
            "* **Placa de vídeo:** NVIDIA GeForce RTX 3070 Ti ou AMD Radeon RX 6800 XT\n",
            "* **Memória RAM:** 32 GB de DDR4-3600 ou DDR5-5200\n",
            "* **Armazenamento:** SSD NVMe de 1 TB ou 2 TB\n",
            "\n",
            "**Dicas adicionais:**\n",
            "\n",
            "* Considere uma placa-mãe com um bom sistema de fornecimento de energia (VRM) para suportar processadores de alto desempenho.\n",
            "* Aumente a memória RAM se você planeja trabalhar com arquivos grandes ou complexos.\n",
            "* Um SSD NVMe oferece tempos de carregamento mais rápidos e melhor desempenho geral.\n",
            "* Certifique-se de que seu gabinete tenha espaço suficiente para todos os componentes e permita um fluxo de ar adequado.\n",
            "\n",
            "Esta configuração fornecerá um desempenho responsivo e confiável para trabalhos do AutoCAD, incluindo modelagem 3D, desenho 2D e renderização.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(edibot('Muito Obrigado', []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "xHaUwnsba5NR",
        "outputId": "a48ae1eb-d126-4e08-d9ea-abbc7ae4dcef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá,\n",
            "\n",
            "Obrigado por entrar em contato com a ByteMe. Agradecemos sua confiança em nossos serviços.\n",
            "\n",
            "Nossa equipe está empenhada em fornecer suporte técnico excepcional e soluções personalizadas para atender às suas necessidades de TI.\n",
            "\n",
            "Estamos ansiosos para ajudá-lo com quaisquer dúvidas ou problemas que você possa ter.\n",
            "\n",
            "Atenciosamente,\n",
            "Equipe de Atendimento ao Cliente da ByteMe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Uso do GRADIO"
      ],
      "metadata": {
        "id": "sh69Q2xahcVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V4mgmMdAt7WQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb0bcc5-cae0-4079-f61a-1cf87d333414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.29.0-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.1 (from gradio)\n",
            "  Downloading gradio_client-0.16.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=10f433701d1c5f4e5217656414fab7e5a19044956da5a5cca1264d2a0d2d5fbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 ffmpy-0.3.2 gradio-4.29.0 gradio-client-0.16.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "3o_zOvN_iDMd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tela Gráfica para o BOT"
      ],
      "metadata": {
        "id": "9ooAl5x2iTTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(edibot,\n",
        "                 title='BatePapo BiteMe',\n",
        "                 textbox=gr.Textbox(placeholder=\"Pergunte ao EDIBOT\"),\n",
        "                 retry_btn=None).launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QpUOp2JciYtu",
        "outputId": "c539963c-ac34-4e59-dc6f-70ef0a1062f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://0bee1900c793b6ffc6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0bee1900c793b6ffc6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 527, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1856, in process_api\n",
            "    data = await self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1684, in postprocess_data\n",
            "    prediction_value = block.postprocess(prediction_value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py\", line 227, in postprocess\n",
            "    self._postprocess_chat_messages(message_pair[1]),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py\", line 192, in _postprocess_chat_messages\n",
            "    return FileMessage(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pydantic/main.py\", line 176, in __init__\n",
            "    self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
            "pydantic_core._pydantic_core.ValidationError: 1 validation error for FileMessage\n",
            "alt_text\n",
            "  Input should be a valid string [type=string_type, input_value=parts {\n",
            "  text: \"**Config...quado.\"\n",
            "}\n",
            "role: \"model\"\n",
            ", input_type=Content]\n",
            "    For further information visit https://errors.pydantic.dev/2.7/v/string_type\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subir para o GitHub"
      ],
      "metadata": {
        "id": "eh6GfbuM1oXq"
      }
    }
  ]
}